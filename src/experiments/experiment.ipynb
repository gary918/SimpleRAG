{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/fqvj3tk53cs3jlwwkf6wqx880000gn/T/ipykernel_54488/1116794850.py:16: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
      "/var/folders/1t/fqvj3tk53cs3jlwwkf6wqx880000gn/T/ipykernel_54488/1116794850.py:20: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedder = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Ollama\n",
    "import os\n",
    "\n",
    "# Load the PDF\n",
    "loader = PDFPlumberLoader(\"../data/prepguide.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Instantiate the embedding model\n",
    "embedder = HuggingFaceEmbeddings()\n",
    "\n",
    "# Create the vector store and fill it with embeddings\n",
    "vector = FAISS.from_documents(documents, embedder)\n",
    "retriever = vector.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/fqvj3tk53cs3jlwwkf6wqx880000gn/T/ipykernel_54488/2607495157.py:7: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"deepseek-r1\")\n",
      "/var/folders/1t/fqvj3tk53cs3jlwwkf6wqx880000gn/T/ipykernel_54488/2607495157.py:20: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(\n",
      "/var/folders/1t/fqvj3tk53cs3jlwwkf6wqx880000gn/T/ipykernel_54488/2607495157.py:31: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain/\n",
      "  combine_documents_chain = StuffDocumentsChain(\n",
      "/var/folders/1t/fqvj3tk53cs3jlwwkf6wqx880000gn/T/ipykernel_54488/2607495157.py:37: LangChainDeprecationWarning: This class is deprecated. Use the `create_retrieval_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/\n",
      "  qa = RetrievalQA(\n",
      "/var/folders/1t/fqvj3tk53cs3jlwwkf6wqx880000gn/T/ipykernel_54488/2607495157.py:44: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa(user_input)[\"result\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "1. Use the following pieces of context to answer the question at the end.\n",
      "2. If you don't know the answer, just say that \"I don't know\" but don't make up an answer on your own.\n",
      "\n",
      "3. Keep the answer crisp and limited to 3,4 sentences.\n",
      "Context: Context:\n",
      "content:Google Interview Preparation Guide\n",
      "Customer Engineer Specialist\n",
      "Our hiring process\n",
      "There’s no one kind of Googler, so we’re always looking for people who can bring new\n",
      "perspectives and experiences to our teams. If you’re looking for a place that values your\n",
      "curiosity, passion, and desire to learn, if you’re seeking colleagues who are big thinkers eager to\n",
      "take on fresh challenges as a team, you may be a future Googler. The Interviews\n",
      "Google Cloud’s interview process consists of two parts during which we evaluate four\n",
      "attributes: Role Related Knowledge, General Cognitive Ability, Googleyness, and Leadership. 1.\n",
      "source:../data/prepguide.pdf\n",
      "\n",
      "Context:\n",
      "content:Technical Role Related Knowledge (45 Minutes)\n",
      "2. General Cognitive Ability (45 Minutes)\n",
      "3. Googleyness & Leadership (45 Minutes)\n",
      "4. Sales RRK (Consultative Skills) + Panel Presentation (45 Minutes)\n",
      "(1) Technical Role Related Knowledge\n",
      "With Role-Related Knowledge (RRK), we’ll dig into two primary areas: cloud foundational\n",
      "knowledge and technical depth. This interview won’t include coding, but you should be\n",
      "prepared to illustrate solutions on a whiteboard. In addition to evaluating your broad\n",
      "knowledge of cloud technologies, interviewers will evaluate your depth in the domain area of\n",
      "the specialist role to which you’re applying. Each specialist RRK interview is different. Use the index below to navigate to the appropriate\n",
      "role, and use the info provided as a starting point for your preparation. If you’re unclear which\n",
      "role you’re interviewing for, ask your recruiter. Although you’re encouraged to leverage your hands-on experience across any cloud platforms,\n",
      "it’s recommended to study the Google Cloud Platform (GCP), and be able to tie your\n",
      "experience into GCP tools and offerings. We highly recommend studying GCP whitepapers and\n",
      "using your Gmail account to play around in the console, if applicable. careers.google.com\n",
      "\n",
      "source:../data/prepguide.pdf\n",
      "\n",
      "Context:\n",
      "content:Although technical, this interview won’t include coding\n",
      "questions. Concepts to understand\n",
      "● Data protection\n",
      "● Identity and access management\n",
      "● Network security\n",
      "● Typical security threats to Cloud environments and mitigation techniques\n",
      "● Compliance (e.g., ISO 27001, SOC 2 and 3, FedRAMP, PCI DSS, HIPAA, and GDPR)\n",
      "GCP technologies to study up on\n",
      "● Google Cloud Security\n",
      "● Google Cloud Compliance resource center\n",
      "● Google Cloud Security best practices center\n",
      "Other suggested links\n",
      "● Google Cloud Whitepapers\n",
      "careers.google.com\n",
      "\n",
      "source:../data/prepguide.pdf\n",
      "Question: What is the process of a Google Cloud's interview process?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "<think>\n",
      "Okay, so I need to figure out what the process for a Google Cloud interview is. Let me see... The user provided some context from Google's interview preparation guide for a Customer Engineer Specialist role.\n",
      "\n",
      "First, they mentioned that there are four main attributes they evaluate during the interviews: Role Related Knowledge, General Cognitive Ability, Googleyness, and Leadership. Each of these has different sections or parts associated with it.\n",
      "\n",
      "Looking at the Technical Role-Related Knowledge section, it's split into two areas: cloud foundational knowledge and technical depth. They don't have coding questions but expect solutions to be worked out on a whiteboard. Preparation should include studying GCP resources like whitepapers and possibly using Gmail for console exploration.\n",
      "\n",
      "The General Cognitive Ability part isn't detailed in the provided context, so I can't say much about that unless there's more information elsewhere. \n",
      "\n",
      "Googleyness refers to how well someone integrates into Google culture, which includes things like using Google tools effectively, understanding their ecosystem, and being familiar with phrases or practices within Google.\n",
      "\n",
      "The last section mentions Sales RRK (Consultative Skills) plus a panel presentation. This probably means they assess soft skills like communication, negotiation, and presentation abilities during interviews.\n",
      "\n",
      "Putting it all together, the process involves several stages each evaluating different attributes. The first part is the technical interview focusing on cloud knowledge and depth, followed by General Cognitive Ability. Then Googleyness and Leadership are assessed, possibly through more interactive or scenario-based interviews. Finally, there's a sales-related component involving presentations.\n",
      "\n",
      "I should structure this into clear points without making it too long. Make sure each part is distinct and covers the main areas mentioned in the context.\n",
      "</think>\n",
      "\n",
      "The Google Cloud interview process for a Customer Engineer Specialist role includes several stages designed to evaluate four key attributes: Technical Role-Related Knowledge, General Cognitive Ability, Googleyness & Leadership, and Sales RRK with a panel presentation.\n",
      "\n",
      "1. **Technical Interview**: Focuses on cloud foundational knowledge and technical expertise. Participants are assessed without coding questions but should prepare solutions for a whiteboard. Study GCP resources such as whitepapers and practice using Gmail in the Cloud Console.\n",
      "\n",
      "2. **General Cognitive Ability**: Although not detailed here, this section likely evaluates problem-solving and analytical skills through various exercises or case studies during interviews.\n",
      "\n",
      "3. **Googleyness & Leadership**: Assesses integration into Google culture, knowledge of GCP tools, understanding of Google's ecosystem, and familiarity with relevant phrases or practices within the company.\n",
      "\n",
      "4. **Sales RRK & Panel Presentation**: Evaluates consultative skills, communication abilities, and presentation techniques through panel presentations where candidates discuss their experiences and expertise in a structured format.\n",
      "\n",
      "This comprehensive approach ensures that candidates are evaluated on both technical proficiency and cultural fit within Google's environment.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Define llm\n",
    "llm = Ollama(model=\"deepseek-r1\")\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"\"\"\n",
    "1. Use the following pieces of context to answer the question at the end.\n",
    "2. If you don't know the answer, just say that \"I don't know\" but don't make up an answer on your own.\\n\n",
    "3. Keep the answer crisp and limited to 3,4 sentences.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt)\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=QA_CHAIN_PROMPT,\n",
    "    callbacks=None,\n",
    "    verbose=True)\n",
    "\n",
    "document_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\", \"source\"],\n",
    "    template=\"Context:\\ncontent:{page_content}\\nsource:{source}\",\n",
    ")\n",
    "\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"context\",\n",
    "    document_prompt=document_prompt,\n",
    "    callbacks=None)\n",
    "\n",
    "qa = RetrievalQA(\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    verbose=True,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True)\n",
    "\n",
    "user_input = \"What is the process of a Google Cloud's interview process?\"\n",
    "response = qa(user_input)[\"result\"]\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
